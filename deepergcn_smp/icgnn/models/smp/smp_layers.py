import torch
import torch.nn as nn
from torch import Tensor
from torch_geometric.nn import MessagePassing
from icgnn.models.smp.layers import XtoX, UtoU, EntrywiseU, EntryWiseX


class SimplifiedFastSMPLayer(MessagePassing):
    def __init__(
        self, in_features: int, num_towers: int, out_features: int, use_x: bool
    ):
        super().__init__(aggr="add", node_dim=-3)
        self.use_x = use_x
        self.message_nn = (XtoX if use_x else UtoU)(
            in_features, out_features, bias=True
        )
        if self.use_x:
            self.alpha = nn.Parameter(torch.zeros(1, out_features), requires_grad=True)
        else:
            self.alpha = nn.Parameter(
                torch.zeros(1, 1, out_features), requires_grad=True
            )

    def reset_parameters(self):
        self.message_nn.reset_parameters()
        self.alpha.requires_grad_(False)
        self.alpha[...] = 0
        self.alpha.requires_grad_(True)

    def forward(self, u, edge_index, batch_info):
        """x corresponds either to node features or to the local context, depending on use_x."""
        n = batch_info["num_nodes"]
        if self.use_x and u.dim() == 1:
            u = u.unsqueeze(-1)
        u = self.message_nn(u, batch_info)
        new_u = self.propagate(edge_index, size=(n, n), u=u)
        # Normalization
        if len(new_u.shape) == 2:
            # node features are used
            new_u /= batch_info["average_edges"][:, :, 0]
        else:
            # local contexts are used
            new_u /= batch_info["average_edges"]
        return new_u

    def message(self, u_j: Tensor):
        return u_j

    def update(self, aggr_u, u):
        return aggr_u + u + self.alpha * u * aggr_u


class FastSMPLayer(MessagePassing):
    def __init__(
        self, in_features: int, num_towers: int, out_features: int, use_x: bool
    ):
        super().__init__(aggr="add", node_dim=-2 if use_x else -3)
        self.use_x = use_x
        self.in_u, self.out_u = in_features, out_features
        if use_x:
            self.message_nn = XtoX(in_features, out_features, bias=True)
            self.linu_i = EntryWiseX(
                out_features, out_features, num_towers=out_features
            )
            self.linu_j = EntryWiseX(
                out_features, out_features, num_towers=out_features
            )
        else:
            self.message_nn = UtoU(
                in_features, out_features, n_groups=num_towers, residual=False
            )
            self.linu_i = EntrywiseU(
                out_features, out_features, num_towers=out_features
            )
            self.linu_j = EntrywiseU(
                out_features, out_features, num_towers=out_features
            )

    def forward(self, u, edge_index, batch_info):
        n = batch_info["num_nodes"]
        u = self.message_nn(u, batch_info)
        new_u = self.propagate(edge_index, size=(n, n), u=u)
        new_u /= batch_info["average_edges"]
        return new_u

    def message(self, u_j):
        return u_j

    def update(self, aggr_u, u):
        a_i = self.linu_i(u)
        a_j = self.linu_j(aggr_u)
        return aggr_u + u + a_i * a_j


class SMPLayer(MessagePassing):
    def __init__(
        self, in_features: int, num_towers: int, out_features: int, use_x: bool
    ):
        super().__init__(aggr="add", node_dim=-3)
        self.use_x = use_x
        self.in_u, self.out_u = in_features, out_features
        if use_x:
            self.message_nn = XtoX(in_features, out_features, bias=True)
            self.order2_i = EntryWiseX(out_features, out_features, num_towers)
            self.order2_j = EntryWiseX(out_features, out_features, num_towers)
            self.order2 = EntryWiseX(out_features, out_features, num_towers)
        else:
            self.message_nn = UtoU(
                in_features, out_features, n_groups=num_towers, residual=False
            )
            self.order2_i = EntrywiseU(out_features, out_features, num_towers)
            self.order2_j = EntrywiseU(out_features, out_features, num_towers)
            self.order2 = EntrywiseU(out_features, out_features, num_towers)
        self.update1 = nn.Linear(2 * out_features, out_features)
        self.update2 = nn.Linear(out_features, out_features)

    def forward(self, u, edge_index, batch_info):
        n = batch_info["num_nodes"]
        u = self.message_nn(u, batch_info)
        u1 = self.order2_i(u)
        u2 = self.order2_j(u)
        new_u = self.propagate(edge_index, size=(n, n), u=u, u1=u1, u2=u2)
        new_u /= batch_info["average_edges"]
        return new_u

    def message(self, u_j, u1_i, u2_j):
        order2 = self.order2(torch.relu(u1_i + u2_j))
        return order2

    def update(self, aggr_u, u):
        up1 = self.update1(torch.cat((u, aggr_u), dim=-1))
        up2 = up1 + self.update2(up1)
        return up2


class SMPLayer(MessagePassing):
    def __init__(
        self,
        in_features: int,
        num_towers: int,
        out_features: int,
        edge_features: int,
        use_x: bool,
        use_edge_features: bool,
    ):
        """Use a MLP both for the update and message function + edge features."""
        super().__init__(aggr="add", node_dim=-2 if use_x else -3)
        self.use_x, self.use_edge_features = use_x, use_edge_features
        self.in_u, self.out_u, self.edge_features = (
            in_features,
            out_features,
            edge_features,
        )
        self.edge_nn = (
            nn.Linear(edge_features, out_features) if use_edge_features else None
        )

        self.message_nn = (EntryWiseX if use_x else UtoU)(
            in_features, out_features, n_groups=num_towers, residual=False
        )

        args_order2 = [out_features, out_features, num_towers]
        entry_wise = EntryWiseX if use_x else EntrywiseU
        self.order2_i = entry_wise(*args_order2)
        self.order2_j = entry_wise(*args_order2)
        self.order2 = entry_wise(*args_order2)

        self.update1 = nn.Linear(2 * out_features, out_features)
        self.update2 = nn.Linear(out_features, out_features)

    def forward(self, u, edge_index, edge_attr, batch_info):
        n = batch_info["num_nodes"]
        u = self.message_nn(u, batch_info)
        u1 = self.order2_i(u)
        u2 = self.order2_j(u)
        new_u = self.propagate(
            edge_index, size=(n, n), u=u, u1=u1, u2=u2, edge_attr=edge_attr
        )
        new_u /= (
            batch_info["average_edges"][:, :, 0]
            if self.use_x
            else batch_info["average_edges"]
        )
        return new_u

    def message(self, u_j, u1_i, u2_j, edge_attr):
        edge_feat = self.edge_nn(edge_attr) if self.use_edge_features else 0
        if not self.use_x:
            edge_feat = edge_feat.unsqueeze(1)
        order2 = self.order2(torch.relu(u1_i + u2_j + edge_feat))
        u_j = u_j + order2
        return u_j

    def update(self, aggr_u, u):
        up1 = self.update1(torch.cat((u, aggr_u), dim=-1))
        up2 = up1 + self.update2(up1)
        return up2 + u
